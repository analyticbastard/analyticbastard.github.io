
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>The Analytic Bastard</title>
  <meta name="author" content="Analytic Bastard">

  
  <meta name="description" content="SVG files are vector images based on a XML specification for describing geometric shapes (vector images). The fact that the image itself is an XML &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://analyticbastard.github.io">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="The Analytic Bastard" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script src="https://ajax.googleapis.com/ajax/libs/jqueryui/1.8.16/jquery-ui.min.js" type="text/javascript"></script>
  <script src="//netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/lib<n/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<script type="text/javascript" src="https://www.google.com/jsapi"></script>
<script type="text/javascript">google.load("feeds", "1");</script>

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">The Analytic Bastard</a></h1>
  
    <h2>Making geometers go crazier</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:analyticbastard.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/04/09/manipulating-svg-images-from-browser-javascript/">Manipulating SVG Images From Browser Javascript</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2015-04-09T01:18:48+02:00'><span class='date'><span class='date-month'>Apr</span> <span class='date-day'>9</span><span class='date-suffix'>th</span>, <span class='date-year'>2015</span></span> <span class='time'>1:18 am</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>SVG files are vector images based on a XML specification for describing geometric shapes (vector images). The fact that the image itself is an XML element makes it an ideal candidate to be manipulated from our client-side code. Unfortunately, SVG elements are not entirely treated in the same way that HTML elements are. In particular, they hold an internal DOM.</p>

<p>I am working on a project that involves dealing with a chart produced by the D3.js library, which produces SVG images.</p>

<p>In particular, I could convert a collection of labels whose XML tag was “text” within the SVG image to a Javascript array in this way:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="Javascript"><span class="line"><span class="kd">var</span> <span class="nx">labelArray</span> <span class="o">=</span> <span class="p">[].</span><span class="nx">slice</span><span class="p">.</span><span class="nx">call</span><span class="p">(</span><span class="nb">document</span><span class="p">.</span><span class="nx">getElementsByTagName</span><span class="p">(</span><span class="s2">&quot;text&quot;</span><span class="p">));</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Then I used the Functional Javascript library, which is cool, to select the element I was looking for</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="Javascript"><span class="line"><span class="kd">var</span> <span class="nx">label</span> <span class="o">=</span> <span class="nx">fjs</span><span class="p">.</span><span class="nx">first</span><span class="p">(</span><span class="kd">function</span><span class="p">(</span><span class="nx">elem</span><span class="p">)</span> <span class="p">{</span>
</span><span class="line">                    <span class="c1">// textContent is an attribute of SVG element type</span>
</span><span class="line">                    <span class="k">return</span> <span class="nx">elem</span><span class="p">.</span><span class="nx">textContent</span> <span class="o">===</span> <span class="s2">&quot;ad&quot;</span><span class="p">;</span>
</span><span class="line"><span class="p">})(</span><span class="nx">labelsArray</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>And then set special properties on it, so it would be distinguishable from the rest of the elements:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="Javascript"><span class="line"><span class="nx">label</span><span class="p">.</span><span class="nx">style</span><span class="p">.</span><span class="nx">fontSize</span> <span class="o">=</span> <span class="s2">&quot;20px&quot;</span><span class="p">;</span>
</span><span class="line"><span class="nx">label</span><span class="p">.</span><span class="nx">style</span><span class="p">.</span><span class="nx">fontWeight</span> <span class="o">=</span> <span class="s2">&quot;bold&quot;</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Otherwise, elements with specific ID could be accessed firstly by getting the SVG file content from the SVG DOM element first, then accessing the internal element by ID:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class="Javascript"><span class="line"><span class="kd">var</span> <span class="nx">a</span> <span class="o">=</span> <span class="nb">document</span><span class="p">.</span><span class="nx">getElementById</span><span class="p">(</span><span class="s2">&quot;imagesvg&quot;</span><span class="p">);</span>
</span><span class="line"><span class="nx">a</span><span class="p">.</span><span class="nx">addEventListener</span><span class="p">(</span><span class="s2">&quot;load&quot;</span><span class="p">,</span><span class="kd">function</span><span class="p">(){</span>
</span><span class="line">            <span class="kd">var</span> <span class="nx">svgDoc</span> <span class="o">=</span> <span class="nx">a</span><span class="p">.</span><span class="nx">contentDocument</span><span class="p">;</span> <span class="c1">//get the inner DOM of image.svg</span>
</span><span class="line">            <span class="kd">var</span> <span class="nx">delta</span> <span class="o">=</span> <span class="nx">svgDoc</span><span class="p">.</span><span class="nx">getElementById</span><span class="p">(</span><span class="s2">&quot;delta&quot;</span><span class="p">);</span> <span class="c1">//get the inner element by id</span>
</span><span class="line"><span class="p">},</span><span class="kc">false</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Notice that the file is called image.svg and that the browser can load it asynchronously, and that’s the reason for the load event handler.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/03/25/installing-theano-on-windows/">Installing Theano on Windows</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2015-03-25T00:56:43+01:00'><span class='date'><span class='date-month'>Mar</span> <span class='date-day'>25</span><span class='date-suffix'>th</span>, <span class='date-year'>2015</span></span> <span class='time'>12:56 am</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Since Theano team works under Linux, a non-trivial amount of hacking is required to get it working on Windows.</p>

<p>In this post I assume you are going with <a href="http://www.lfd.uci.edu/~gohlke/pythonlibs/">Cristoph Gohlke’s packages</a> (for reasons, read <a href="blog/2015/02/26/powering-up-python-as-a-data-analysis-platform/">here</a>)</p>

<p>Make sure you also have MS Visual C++ and the NVidia CUDA Toolkit. If you don’t have it, add the Visual C++ cl.exe compiler’s directory to the path. Mine was under C:\Program Files (x86)\Microsoft Visual Studio 10\VC\bin.</p>

<p>First think you need, after installing Theano, is the nose package, since Gohlke’s build needs it at initialization time. Download it and install it from Gohlke’s site along with Theano.</p>

<p>Next, you need this .theanorc to be put under your home directory under <code>C:\USER\&lt;yourname&gt;</code></p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class=""><span class="line">[global]device = gpu
</span><span class="line">[nvcc]compiler_bindir=C:\Program Files (x86)\Microsoft Visual Studio 10.0\VC\bin# flags=-m32 # we have this hard coded for now
</span><span class="line">[blas]ldflags =# ldflags = -lopenblas # placeholder for openblas support</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>I am not very sure how to use OpenBLAS from here. I assume that if all CPU operations are done via Numpy and SciPy, then their default BLAS routines are used, and no direct call to a third BLAS implementation is made, but who knows! (Well, I looked into it a little bit and it seems Theano calls BLAS directly, I guess you may want to install OpenBLAS).</p>

<p>OK, we have the NVidia compiler and tools, the MS compiler that nvcc needs and the configuration. The last thing we need is to install a GNU C and C++ compiler that supports 64 bit Windows binary creation. There is a project called MinGW-w64 that does that. I recommend to download a <a href="http://sourceforge.net/projects/mingw-w64/files/Toolchains%20targetting%20Win64/Personal%20Builds/rubenvb/gcc-4.8-release/">private build from the user rubenvb</a> that does not come along with the Python environment embedded as the more official build does. Put the bin directory (where GCC is located) of that installation in the Path (Control panel, etc). Theano needs this to compile the symbolic operations to object code and then to CUDA kernels if applicable, I presume.</p>

<p>If you run into errors of type “GCC: sorry, unimplemented: 64-bit mode not compiled in”, then your MinGW is not x86_64 compliant. The NVidia compiler nvcc can also complain if it finds no cl.exe in the path.</p>

<p>By the way, all of this was to use deep learning techniques for Kaggle competitions, so the intended consequence was to install PyLearn2. This is not listed under Gohlke’s libraries, but it is not low level and all is based on Theano and maybe other numerical packages such as Numpy. Being a pure Python package, you need to clone it from Github:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">git clone git://github.com/lisa-lab/pylearn2.git
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>And then perform</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line"><span class="nb">cd </span>pylearn2
</span><span class="line">python setup.py install
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>There is an easier procedure that will not require you to manually perform the git operations, and it is through pip</p>

<p><code>bash
pip install git+git://github.com/lisa-lab/pylearn2.git
</code>`</p>

<p>You have pip under your Python installation, within the Scripts directory, in the case it came with Python, or if you got Gohlke’s installer.</p>

<p>This will also leave the module correctly accessible through Python.</p>

<p>Pylearn2’s tutorial test is a little bit complicated to be a “hello world” test, so I looked for another quick example to see if my installation was finished. A very nice one popped up in <a href="http://www.arngarden.com/2013/07/29/neural-network-example-using-pylearn2/">this link</a>. But first I have to tell that this made me realize that Gohlke’s Theano is missing three files, something very, very strange since they are called from within Theano. In particular, the module missing is everything under theano.compat. In this case, just copy the contents from Theano’s <a href="https://github.com/Theano/Theano/blob/master/theano/compat">Github repository</a> directory compat to a compat directory created on your local theano installation under Python 2.7 (mine C:\Python27\Lib\site-packages\theano).</p>

<p>After that, run the code in <a href="https://gist.github.com/arngarden/6087798">this link</a>, which is a neural network solving the XOR problem. And we are done.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/03/08/the-monty-hall-problem-my-explanation/">The Monty Hall Problem (My Explanation)</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2015-03-08T00:17:17+01:00'><span class='date'><span class='date-month'>Mar</span> <span class='date-day'>8</span><span class='date-suffix'>th</span>, <span class='date-year'>2015</span></span> <span class='time'>12:17 am</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>If I tell you: There are 1K bitcoins 1 wallet that will be yours if you guess which wallet out of three is the right one, the rest containing an amount of zero bitcoins, and ask you to point out an initial selection, then showed you that, effectively, one of the remaining wallets contains zero bitcoins… and finally giving you the opportunity to change wallet. Would you change? The awnser is yes.</p>

<p>This is so because there is new evidence now that supports a higher probability that the remaining unseen wallet is the right choice, whereas there is none about your current choice. The fact that you selected wallet 1, and given that choice, I showed you wallet 2, that leaves wallet 3 with a posterior probability of 2/3. This does not happen for our current wallet 1, since choosing 1 influenced my decision to show you 2. More precisely: You chose wrongly with probability 2/3. With that probability, I show you the only possible door that I can, leaving the 2/3 for the remaining unseen and unchosen door. On the contrary, you choose well with 1/3 probability, but then I can choose among 2 doors to show you, each with a probability of 1/2. This is how we include my decision (or necessity) to show you 2 into the math (this is the best explanation you are gonna get from all over the internet):
Let’s call R “right choice” V “visible incorrect wallet” and S “your choice”. We need to compute <script type="math/tex">P(R=3|V=2,S=1)</script>, the probability of 3 being the right wallet, after you selected 1 and I showed you that 2 was not right (remember that all priors are 1/3).
<script type="math/tex">P(R=3|V=2,S=1)=\frac{P(V=2,S=1|R=3)P(R=3)}{P(V=2,S=1|R=3)P(R=3)+P(V=2,S=1|R=1)P(R=1)}\\=\frac{1\times 1/3}{1\times 1/3 + 1/2 \times 1/3}=2/3</script><script type="math/tex">P(V=2,S=1|R=3)=1</script> is the probability that, given R=3, then I was forced to show you the incorrect wallet remaining (you already chose one incorrect wallet). <script type="math/tex">P(V=2,S=1|R=1)=1/2</script> because there are two possible incorrect wallets (since you selected the correct one) that I can choose from to show you.</p>

<p>Let’s compute the same posterior for the case I decide not to change wallet:
<script type="math/tex">P(R=1|V=2,S=1)=\frac{P(V=2,S=1|R=1)P(R=1)}{P(V=2,S=1|R=3)P(R=3)+P(V=2,S=1|R=1)P(R=1)}\\=\frac{1/2\times 1/3}{1\times 1/3 + 1/2 \times 1/3}=1/3</script>.</p>

<p>Therefore if you change you have more chances of winning the 1000 bitcoins.</p>

<p>Needless to say, this works for every possible combination of <script type="math/tex">R</script>, <script type="math/tex">S</script> and <script type="math/tex">V</script>. 
This happens, as I mentioned, because of the way I was influenced (forced) to show you the incorrect remaining wallets. To see it intuitively, imagine 100 wallets, and that you chose one amongst them, and I am forced to show you 98 incorrect wallets, leaving your choice and another one. Is it more likely that this particular wallet is the correct one (that your choice forced me to leave it) or that you chose wisely amongst 100 wallets? If you choose 99 incorrect wallets, the set that I show you is the same, except for the chosen incorrect wallets each time, and will never contain the particular correct wallet.</p>

<p>There is a cool <a href="https://play.google.com/store/apps/details?id=us.steveo.montyhall">Android app</a> in case you want to check how the law of large numbers works for this problem.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/02/26/powering-up-python-as-a-data-analysis-platform/">Powering Up Python as a Data Analysis Platform</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2015-02-26T00:01:36+01:00'><span class='date'><span class='date-month'>Feb</span> <span class='date-day'>26</span><span class='date-suffix'>th</span>, <span class='date-year'>2015</span></span> <span class='time'>12:01 am</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>When working with Machine Learning algorithms we face large data movement, but in many algorithms the most important part is a heavy use of linear algebra operations and other mathematical/vectorial computations.</p>

<p>Intel has a math library that is optimized for the latest processors (MKL), including programmer-made optimizations for multiple core counts, wider vector units and more varied architectures which yield a performance that could not be achieved only with compiler automated optimization for routines such as highly vectorized and threaded linear algebra, fast Fourier transforms, and vector math and Statistics. These functions are royalty-free, so including them statically in the program comes at no cost.</p>

<p>Cristoph Gohlke and collaborators have a MKL license and have taken the effort to compile a series of Python modules compiled agaist them. In particular, Numpy and Scipy include these powerful libraries. Add to this that he has already compiled the binaries for Windows 64 bits which are very rare on the internet.</p>

<p>The following are two tests with a positive definite matrix. We compute the eigenvalues in R and Python, using the symmetric eigenvalue solver in each case. The processor is a i5 3210M not plugged in to the socket (losing approx. half its performance). Note that this version of R is compiled against standard Atlas libraries.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class="r"><span class="line">B<span class="o">=</span>read.csv<span class="p">(</span><span class="s">&quot;B.csv&quot;</span><span class="p">,</span>header<span class="o">=</span><span class="bp">F</span><span class="p">)</span>
</span><span class="line">st<span class="o">=</span><span class="kp">proc.time</span><span class="p">();</span> eigB<span class="o">=</span><span class="kp">eigen</span><span class="p">(</span>B<span class="p">,</span>symmetric<span class="o">=</span><span class="bp">T</span><span class="p">);</span> en<span class="o">=</span><span class="kp">proc.time</span><span class="p">()</span>
</span><span class="line"><span class="o">&gt;</span> en<span class="o">-</span>st
</span><span class="line">   user  system elapsed
</span><span class="line">   <span class="m">0.58</span>    <span class="m">0.00</span>    <span class="m">0.58</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>In Python:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">time</span>
</span><span class="line"><span class="kn">import</span> <span class="nn">numpy</span>
</span><span class="line"><span class="n">B</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="s">&quot;B.csv&quot;</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s">&quot;,&quot;</span><span class="p">)</span>
</span><span class="line"><span class="n">st</span> <span class="o">=</span> <span class="n">time</span><span class="p">();</span> <span class="n">U</span><span class="p">,</span> <span class="n">E</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigh</span><span class="p">(</span><span class="n">B</span><span class="p">);</span> <span class="n">en</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
</span><span class="line"><span class="o">&gt;&gt;&gt;</span> <span class="n">en</span><span class="o">-</span><span class="n">st</span>
</span><span class="line"><span class="mf">0.13400006294250488</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>A final remark is that there exists an opensource alternative to high-performance CPU computing, and it is the OpenBLAS libraries. Their performance is comparable to MKL.</p>

<p>Link to the positive definite matrix used in the experiments <a href="https://www.dropbox.com/s/uxijs3jckckafra/B.7z">here</a>.
Link to Christoph Gohlke’s page <a href="http://www.lfd.uci.edu/~gohlke/pythonlibs/">here</a>.</p>

<p>Despite the fact that I’ve been aware of Scikits Learn (sklearn) for some time during my postgraduate years, I never got the chance to really use Python for data analysis and, instead, I had been a victim of my own inertia and limited myself to use R and especially Matlab.</p>

<p>I must say, in the beginning, Python looks awkward: it was inconceivable for me to use an invisible element (spaces or tabs) as a structural construction of a program (defining blocks), in a way much similar to Fortran, which I always considered weird (coming from the C world). This and the lack of the omnipresent, C-syntax end-of-line semicolon, prove to be a major boosting element when programming in Python. I must say that whatever lack in computer performance is overcome by the speed the programmer experiences when writing the software. This applies to general software, such as the App server that I am preparing, which is being written in Python using the Google App Engine, and I have to say that it just runs smoothly, no need for recompilations, clear syntax and one-line complex data-processing pieces of code.</p>

<p>Regarding data analysis, it is a little more complicated than Matlab’s clear orientation towards numerical linear algebra (where everything is a Matrix). Good comparisons and reasons supporting my view are</p>

<ul>
  <li><a href="https://sites.google.com/site/pythonforscientists/python-vs-matlab">https://sites.google.com/site/pythonforscientists/python-vs-matlab</a></li>
  <li><a href="http://www.stat.washington.edu/~hoytak/blog/whypython.html">http://www.stat.washington.edu/~hoytak/blog/whypython.html</a></li>
  <li><a href="http://stevetjoa.com/305/">http://stevetjoa.com/305/</a></li>
</ul>

<p>Now, going to Machine Learning specifics, sklearn has everything you need for the majority of the work a machine learning practitioner will ever need.</p>

<ul>
  <li>Data preprocessors, including text vectorizers and TF IDF preprocessors</li>
  <li>SVM implementations</li>
  <li>Stochastic Gradient Descent algorithms for fast regression and classification</li>
  <li>Random Forest and other ensemble methods for robust regression and classification</li>
  <li>Clustering algorithms</li>
  <li>Data dimensionality reduction algorithms such as LLE, ISOMAP and spectral embeddings</li>
  <li>Results presentation, including mean squared error for regression and precision/recall tables for classification. It even computes the area under the ROC curve.</li>
</ul>

<p>This, added to the clean, standardized and well-designed interface, which always has a .fit method for every object which performs the task of learning from samples, and then either a .transform method if the learning is unsupervised (such as LLE, ISOMAP, ICA, PCA, or the preprocessors, etc) or .predict if the learning is supervised (SVM, SGD, ensemble…). If enables a pipelining mechanism that allows us to build the whole pipeline from data reading to results output.</p>

<p>One of the lead programmers of the project, <a href="peekaboo-vision.blogspot.com.es">Andreas Müller</a> has a very insightful blog.</p>

<p>I decided to be more active on Kaggle. For the moment I scored 13th on the Leaderboard of the Amazon employee access competition that recently opened.</p>

<p>Last but not least, just to comment that future work seems to be bent on using the GPU to perform all the linear algebra. Check out</p>

<ul>
  <li><a href="http://www.cs.toronto.edu/~tijmen/gnumpy.html">Gnumpy</a></li>
  <li><a href="http://deeplearning.net/tutorial/DBN.html">Deep Belief Networks</a></li>
  <li><a href="http://documen.tician.de/pycuda/tutorial.html">PyCUDA</a></li>
</ul>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/02/20/image-pan-sharpening-with-pca/">Image Pan-sharpening With PCA</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2015-02-20T11:27:48+01:00'><span class='date'><span class='date-month'>Feb</span> <span class='date-day'>20</span><span class='date-suffix'>th</span>, <span class='date-year'>2015</span></span> <span class='time'>11:27 am</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>There is a collection of methods that are denominated image pan-sharpening, since they use
information available in multiple bands to create an image output that enjoys properties
from all sources, while minimizing drawbacks. The sources combined will contain several
frequency bands, maybe hundreds or thousands. In this case, we are interested in combining
a source with a high resolution but in gray scale, and a RGB image.</p>

<p>This is especially important in satellite imagery, since satellites often incorporate
a multispectral camera with limited resolution and a high-resolution, low-band/grayscale
camera among their equipment.</p>

<p>To play with this, we will use Matlab (since I’ve worked a little bit with its image
functions and array transformations, and this job will be quick)</p>

<h2 id="data-preparation">Data preparation</h2>

<p>We first load original image (included in Matlab)</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="matlab"><span class="line"><span class="n">peppers</span> <span class="p">=</span> <span class="n">imread</span><span class="p">(</span><span class="s">&#39;peppers.png&#39;</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><img class="center" src="/images/peppers.png" title="Original image" alt="images" /></p>

<p>Now we simulate uniband (grayscale) and multiband (downscaled) imagery</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="matlab"><span class="line"><span class="n">multiband</span> <span class="p">=</span> <span class="n">imresize</span><span class="p">(</span><span class="n">peppers</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">);</span>
</span><span class="line"><span class="n">uniband</span> <span class="p">=</span> <span class="n">rgb2gray</span><span class="p">(</span><span class="n">peppers</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>The multiband image looks like this</p>

<p><img class="center" src="/images/multiband.png" title="Multiband image" alt="images" /></p>

<p>And the high resolution (low band) image looks like this</p>

<p><img class="center" src="/images/uniband.png" title="High resolution image" alt="images" /></p>

<p>In the first case, we resize the image to a quarter of its size <strong><em>in both dimensions</em></strong>.
This means we loose 15/16 of the information! In the second case we compute a grayscale
image, loosing complementary information.</p>

<p>These two images are the ones we are interested in combining.</p>

<h2 id="image-pan-sharp-with-pca">Image pan-sharp with PCA</h2>

<p>We still need to prepare the data one more time. 
We need to upscale multiband image (again, color image and same size than original but with
the information from the downscaled version) so that we can combine it with the hight
resolution image (adjust its dimensions)</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="matlab"><span class="line"><span class="n">interpolated</span><span class="p">=</span><span class="n">imresize</span><span class="p">(</span><span class="n">multiband</span><span class="p">,[</span><span class="nb">size</span><span class="p">(</span><span class="n">uniband</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="nb">size</span><span class="p">(</span><span class="n">uniband</span><span class="p">,</span><span class="mi">2</span><span class="p">)]);</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><img class="center" src="/images/interpolated.png" title="Interpolated image from the low resolution, hight band image" alt="images" /></p>

<p>The missing information from this image with respect to the original is noticeable
to the eye in form of blur.</p>

<p>We will now perform PCA on the images. To do that we need to convert the images to the
relevant variables we want to consider in the analysis. In this case, we want to extract
the bands of the images, so that we linearize the images, thus turning matrices into
unidimensional vectors. In case of the grayscale image, this is easily done by just
using the <code>(:)</code> operator. Bit in case of the RGB image, we will need to
reshape into a three-dimensional multivariate X = (R, G, B)</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="matlab"><span class="line"><span class="n">X</span><span class="p">=</span><span class="n">double</span><span class="p">(</span><span class="nb">reshape</span><span class="p">(</span><span class="n">interpolated</span><span class="p">,</span><span class="nb">numel</span><span class="p">(</span><span class="n">interpolated</span><span class="p">)</span><span class="o">/</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">));</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>where we have also converted the data type to double so that we can use Matlab functions.</p>

<p>Now we can compute the components and the projections onto the PCA space</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="matlab"><span class="line"><span class="p">[</span><span class="n">C</span><span class="p">,</span><span class="n">Y</span><span class="p">]=</span><span class="n">pca</span><span class="p">(</span><span class="n">X</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>where <code>C</code> is the matrix of loadings and <code>Y</code> is the projections of the data onto
the PCA space.</p>

<p>At this point, out of curiosity, we can compute correlations. Notice that the first
projection will correlate a lot with the univariate, since both capture mean luminosity
levels, which is an indicator of which component can be substituted by the higher
resolution grayscale image.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="matlab"><span class="line"><span class="n">corrcoef</span><span class="p">(</span><span class="n">Y</span><span class="p">(:,</span><span class="mi">1</span><span class="p">),</span><span class="n">double</span><span class="p">(</span><span class="n">uniband</span><span class="p">(:)))</span>
</span><span class="line"><span class="n">corrcoef</span><span class="p">(</span><span class="n">Y</span><span class="p">(:,</span><span class="mi">2</span><span class="p">),</span><span class="n">double</span><span class="p">(</span><span class="n">uniband</span><span class="p">(:)))</span>
</span><span class="line"><span class="n">corrcoef</span><span class="p">(</span><span class="n">Y</span><span class="p">(:,</span><span class="mi">3</span><span class="p">),</span><span class="n">double</span><span class="p">(</span><span class="n">uniband</span><span class="p">(:)))</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>The first one yields around <code>0.98</code>. Substitute the component now</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="matlab"><span class="line"><span class="n">Z</span><span class="p">=</span><span class="n">Y</span><span class="p">;</span>
</span><span class="line"><span class="n">Z</span><span class="p">(:,</span><span class="mi">1</span><span class="p">)=(</span><span class="n">double</span><span class="p">(</span><span class="n">uniband</span><span class="p">(:)</span><span class="o">-</span><span class="n">min</span><span class="p">(</span><span class="n">uniband</span><span class="p">(:)))</span><span class="o">./</span><span class="n">double</span><span class="p">(</span><span class="n">max</span><span class="p">(</span><span class="n">uniband</span><span class="p">(:))</span><span class="o">-</span><span class="n">min</span><span class="p">(</span><span class="n">uniband</span><span class="p">(:))))</span><span class="o">*</span><span class="p">(</span><span class="n">max</span><span class="p">(</span><span class="n">Y</span><span class="p">(:,</span><span class="mi">1</span><span class="p">))</span><span class="o">-</span><span class="n">min</span><span class="p">(</span><span class="n">Y</span><span class="p">(:,</span><span class="mi">1</span><span class="p">)))</span><span class="o">+</span><span class="n">min</span><span class="p">(</span><span class="n">Y</span><span class="p">(:,</span><span class="mi">1</span><span class="p">));</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>We are adapting the maximum and minimum luminosity of the grayscale image to match
that of the first component.</p>

<p>We now project the new components back to the original RGB space. The matrix <code>C</code> is not
orthonormal, so that we don’t get a properly scaled representation, so we do it manually
(we could also make the matrix <code>C</code> orthonormal, though the effect of changing the first
component would have impacted the final luminosity levels and thus we still would have needed
to rescale the colors)</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="matlab"><span class="line"><span class="n">G</span><span class="p">=</span><span class="n">Z</span><span class="o">*</span><span class="n">C</span><span class="o">&#39;</span><span class="p">;</span>
</span><span class="line"><span class="n">I</span> <span class="p">=</span> <span class="p">(</span><span class="n">G</span> <span class="o">-</span> <span class="n">min</span><span class="p">(</span><span class="n">G</span><span class="p">(:)))</span><span class="o">/</span><span class="p">(</span><span class="n">max</span><span class="p">(</span><span class="n">G</span><span class="p">(:))</span><span class="o">-</span><span class="n">min</span><span class="p">(</span><span class="n">G</span><span class="p">(:)));</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Lastly we reshape from (R, G, B) multivariate to an RGB image</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="matlab"><span class="line"><span class="n">merged</span> <span class="p">=</span> <span class="nb">reshape</span><span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="nb">size</span><span class="p">(</span><span class="n">interpolated</span><span class="p">));</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>The result shows that, effectively, we enjoy the best part of the two worlds</p>

<p><img class="center" src="/images/merged.png" title="Merged image" alt="images" /></p>

<p>As mentioned, we could play with the luminiscence levels to attain a color more loyal
to the original.</p>

<p>The reason why this works is that the first PCA component takes most of the information,
thus creating a sort of best fit for all colors in the RGB spectrum. This is a kind of
luminiscence, which is what the grayscape image is and what we substitute it by.</p>

<p>Donwload full Matlab program form <a href="https://github.com/analyticbastard/pansharpening-pca">Github</a></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/02/08/google-original-page-rank/">Google&#8217;s Original Page Rank Implementation</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2015-02-08T11:31:03+01:00'><span class='date'><span class='date-month'>Feb</span> <span class='date-day'>8</span><span class='date-suffix'>th</span>, <span class='date-year'>2015</span></span> <span class='time'>11:31 am</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Ever since I took a good course on Matrix Analysis, I have been curious about how Google’s Page Rank algorithm was
related to Matrix theory, because I never got a chance to have a look at it when I studied computer systems.</p>

<p>Imagine the graph of web pages visited by Google crawlers, where <script type="math/tex">\mathbf{M}</script> is the adjacency matrix with the outgoing
links in the columns, where each edge in the web page <script type="math/tex">i</script> pointing to a web page <script type="math/tex">j</script> (which can be the same)
has a score of <script type="math/tex">\frac{1}{n_i}</script>, where <script type="math/tex">n_i</script> is the number of outgoing links in the webpage <script type="math/tex">i</script>. This matrix might
present a number of problems with actual graphs, so what Google did was to include page self references and random
jumps between pages with a small probability given by a parameter <script type="math/tex">\beta</script>.</p>

<script type="math/tex; mode=display">\mathbf{G} = \beta \mathbf{M} + (1-\beta) \frac{\mathbf{1} \mathbf{1}^T}{N}</script>

<p>where <script type="math/tex">N</script> is the total number of web pages in the system and <script type="math/tex">\mathbf{1}</script> is the vector of all ones of size <script type="math/tex">N</script>.</p>

<p><script type="math/tex">\mathbf{G}</script>, being a stochastic matrix, has one as the largest eigenvalue (in module). This can be proved by taking
<script type="math/tex">\mathbf{G}^T \mathbf{1}=\mathbf{1}</script>, and since <script type="math/tex">\mathbf{G}^T = (\mathbf{P}^{-1})^{-T} \mathbf{D} \mathbf{P}{-T}</script>,
where <script type="math/tex">\mathbf{P}</script> diagonalizes <script type="math/tex">\mathbf{G}</script> and <script type="math/tex">\mathbf{D}</script> is the resulting diagonal matrix with the eigenvalues
of both <script type="math/tex">\mathbf{G}</script> and <script type="math/tex">\mathbf{G^{T}}</script>. Thus one is also the largest eigenvalue of <script type="math/tex">\mathbf{G}</script>. Proving that
this is in fact the largest can be done by applyting the <a href="http://en.wikipedia.org/wiki/Gershgorin_circle_theorem">Gershgoring circle theorem</a>.</p>

<p>Intuitively, applyting <script type="math/tex">\mathbf{G}</script> several times has the effect of building a power matrix <script type="math/tex">\mathbf{G}^M</script> whose
largest eigenvalue is also one, but the rest are the power of elements less than one, meaning that each power decreases
all the eigenvalues except the first one. This has the effect of minimizing the component of any vector (the projection)
in the subspace spanned by the eigenvector corresponding to any eigenvalue except the first one. Eventually, all of them
reach zero, leaving only the component of the original vector in the subspace of the eigenvector corresponding to the
largest eigenvalue. This means
<script type="math/tex">\mathbf{G}^M \mathbf{x} \rightarrow \mathbf{w}</script>, as <script type="math/tex">M</script> tends to infinite, where <script type="math/tex">\mathbf{w}</script> is the dominan
eigenvector (the one corresponding to the eigenvalue one).</p>

<p>The elements of this vectors are the important for all the pages registered on the database by the crawlers or
robots.</p>

<p>Obviously this demands a lot of computation since the web is ever changing and this power method would need to be
performed in batch intermitently, so efficient implementations are needed (based on Map Reduce or not).</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/01/10/my-git-workflow/">My Git Workflow</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2015-01-10T01:00:55+01:00'><span class='date'><span class='date-month'>Jan</span> <span class='date-day'>10</span><span class='date-suffix'>th</span>, <span class='date-year'>2015</span></span> <span class='time'>1:00 am</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>In the past I had used CVS as most of the people. Git is much powerful, in so many levels. For starters, you never,
NEVER lose files. You can <strong>always</strong> go back to a previous version, the soft ware, or the hard. But Git requires a little
more attention on the part of the user than other control version systems. This starts by fixing the basic concepts
clearly.</p>

<h3 id="concepts">Concepts</h3>

<p>The concepts, from basic qto more complex, and also sorted by the first time you are likely to come across them, is:</p>

<ul>
  <li><strong>Tracked file</strong>: A file that is under version control. You specifically told Git to track it at some point of its life.</li>
  <li><strong>Woring directory</strong>: This is the classical concept, your working copy of the project, including the files you
modify, the ones that are tracked and others that you want to leave untracked (such as IDE files or personal notes).</li>
  <li><strong>Local repository</strong>: This is <em>the Git repository stored on your local computer</em>. It is <em>not</em> your local working
directory, but the files stored in the <code>.git</code> directory within your working copy.</li>
  <li><strong>remote</strong>: A remote is a remote Git server that stores our project. Several remotes can exist for a project and we
always need to specify the remote to which we are going to send our changes.</li>
  <li><strong>Remote repository</strong>: The remote repository that stores the version of the project that everybody can see.</li>
  <li><strong>Branch</strong>: This is the usual concept of branch. Branches of the project may evolve in an independent way from each
other. All commits are attached to a branch. Local branches may not exist in the remote repository and remote branches
may have not been updated in your local repository at some point. The default branch is called <em>master</em>.</li>
  <li><strong>Conflict</strong>: Incompatible changes from a source were incorporated to a dirty copy (meaning that you modify something
that had been already modified), or you have a commit that modifies something already modified in the source you are
applying. You will need to resolve this by hand.</li>
  <li><strong>stash</strong>: Shelve your local changes. In other words, pack your dirty working copy and leave a clean working directory
that matches the contents of your local repository. This is important if you want to do operations on files that you
have changed on your working copy, since Git will complain otherwise.</li>
  <li><strong>unstash</strong>: Get the changes from the stash into your local copy, making it dirty if it was not. If it was not dirty
or you got changes from another branch or from the remote repository, you are likely to have conflicts and will need
to resolve them.</li>
  <li><strong>pull</strong>: Update remote changes in your local repository (and your working copy so you can see them). If you have
a dirty working copy you will need to stash your local changes.</li>
  <li><strong>Dirty local copy</strong>: Tracked files in the working directory that have been changed.</li>
  <li><strong>commit</strong>: A change in a tracked file (dirty local copy) that gets added to the local repository. You commit to a
branch.</li>
  <li><strong>push</strong>: The commits (local changes that now form part of your local repository) get sent to the remote repository
so that everybody can finally access them. This updates the remote branch.</li>
  <li><strong>merge</strong>: This happens when two members have changed the same tracked files on a branch in the the remote
repository. The last user in pushing the changes (<em>B</em>) will need to pull the changes that the first one (<em>A</em>) already pushed,
so that the official history was written firstly by <em>A</em>. The conflicts will most likely need to be resolved by
hand by <em>B</em>, since Git does not understand any particular language (and is not intelligent to decide on the conflicts
or have criteria to do so). Once merged, <em>B</em> ends up with a dirty working copy, that he needs to commit and then push.
This last push will be accepted by the remote repository server (if no one has put new stuff in the meantime).</li>
  <li><strong>rebase</strong>: This is a especially useful type of merge in which a user has not pulled down changes for a while and there
are a number of commits in the remote repository. If the user commits, then he can rebase the remote branch onto his,
so that his commit is merged on top of the remote commits. The user can then push to the remote branch and see his
changes reflected there. The rebase command is very versatile since it allows us to modify previous commits in our
repository.</li>
  <li><strong>reset</strong>: Set your branch to any commit in your repository. At this point a <strong>VERY IMPORTANT NOTE</strong> must be mentioned:
any repository, including the local one, stores commits. This means that commits <em>ALWAYS</em> survive, they are always
present, and one can always reset a branch head to a particular commit if the commit hash is available. It does not
matter that the commit had been “lost” in the branch chain.</li>
  <li><strong>cherry-pick</strong>: One can also cherry-pick a commit in the repository, given its hash, from any branch and apply it
to any other branch. Again, it does not matter that the picked commit does not currently appear on any branch, it
suffices for it to have been stored in the repository at some point.</li>
  <li><strong>log</strong>: This command is useful since it shows the chain of commits we have on our <em>local</em> repository that end up
in our current state. This does not show all the commits that once belonged to a branch if the branch was reset and
then new commits arrived (in a similar way to when we undo something in MS Word and then write new stuff, we cannot
redo). Useful for rebasing stuff.</li>
  <li><strong>reflog</strong>: This is <strong>ALL</strong> the repository history, including committed stuff, branch changes, pulled changes, etc.
You can find <strong>EVERYTHING</strong> here, even commits that were apparently “lost” from a branch. If you feel you have lost
a commit, just issue <code>git reflog</code> and cherry-pick from there.</li>
</ul>

<h3 id="my-workflow">My workflow</h3>

<p>When you are developing a new feature for your project, want you want to do is branch the master branch (or any other,
but it makes sense to pick up the official state of the project and start from there).</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">git checkout -b newfeature
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>This creates a <strong>local branch</strong>. We are interested in storing our changes remotely so that if something happens to our
local copy (major Git messup that is easy to just ignore and pull the remote, hard drive issues, computer issues,
get your stuff done in some other computer, etc), we have our changes in the remote server too.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">git push origin newfeature
</span><span class="line">git branch --set-origin<span class="o">=</span>origin/newfeature
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>This creates the <strong>remote branch</strong> and sets the default link to our local branch, so that we can push to it.</p>

<p>After this, we can do our changes. I normally spend some time with a feature and by the time I want to commit to master (when the changes are not enough
to be peer reviewed in a pull request to the master branch), some other workmate has committed something, which forces
me to <strong>pull</strong> and <strong>rebase</strong>.</p>

<p>Imagine that I am working on newfeature and I notice that master has changed. It is better to incorporate the remote
changes sooner so that conflicts are minimal. I first <strong>stash</strong> my local changes, since I will need to change branch
to pull master (you can do it from newfeature branch, but I like it this way).</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">git stash
</span><span class="line">git checkout master
</span><span class="line">git pull
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Now we have the remote latest changes. We switch to the newfeature branch</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">git checkout newfeature
</span><span class="line">git rebase -i master
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>This tells git to get (local, which was just updated) commits onto the current branch, newfeature. Now newfeature is
updated with the latest master state. We can keep on working. Get our latest changes, the ones we stashed.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">git stash apply
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>This applies the top of the stash to the current clean local branch, and does not remove them from the stash. I am
normally interested in keeping these changes just in case. I can later remove them with <code>git stash drop</code>. I sometimes
use <code>git stash pop</code> which applies changes <em>and</em> removes them from the stash. If I need to refer to the stash to get
a change that I know was there but am not sure it is on the top, then I use <code>git stash show --name-only</code>, which
gives me the names of the changed files.</p>

<p>When I feel I can commit (because I am done or because I want to store remotely)</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">git commit -m <span class="s2">&quot;Message&quot;</span>
</span><span class="line">git push origin newfeature
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Which saves my commits in the remote branch (remote repository).</p>

<p>I sometimes need to modify something that I committed, because I forgot to include it (and we want our master history
to be clean of mistakes and easy to follow), I prepare my local changes (tracked files) for commit fixup. First I use
the <code>git add</code> command to add these files to the subsequent commit. This commit will be done in a special manner:
using the <code>--fixup=</code> modifier, which accepts the hash of the commit to be modified. This is an extremely versatile
modifier, since it allows us to modify commits buried deep beneath our current head. This creates a new commit chain
with the fixed commit and all the commits that followed it, with new versions adapted to the changes we have introduced
(and of course, all with new hashes, since they are all new commits).</p>

<p>I came across a very easy command pipe to do this, since adding files one by one is a time waster:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">git status <span class="p">|</span> grep modified <span class="p">|</span> cut -d: -f2 <span class="p">|</span> xargs git add
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>The command <code>status</code> gives us the modified files, among other stuff (untracked files, etc). I filter the modified files
(getting only the file name) and then add them as an argument to <code>git add</code>.</p>

<p>We now fix the particular commit. In this case, I get the commit hash with <code>git log</code>.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">git commit --fixup<span class="o">=</span>24ee1df941679953529aabc3d0eef5727a44c094
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>This creates a <em>new</em> commit on top of the rest. We need to squash everything so that git creates the new commit chain,
wich entirely different commits and with the fixing and fixed commits merged into one. If the commit is buried below
the head, you would use the commit previous to the one being fixed. Imagine this chain</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">c0cf52f4a914641efdc635bbc6195b6bef084cdc Categories and other plugin stuff
</span><span class="line">021086446698443ee57858872e14e7ee8ca9e2e5 Remove deploy stuff that got added by mistake
</span><span class="line">24ee1df941679953529aabc3d0eef5727a44c094 First commit to my-source
</span><span class="line">7f49807d5c5651baccb6d66c504549713a7ae7d7 Site updated at 2015-01-05 15:12:45 UTC
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>When you create the fixup commit, it will appear on top of the chain</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">f36806a856994c8365e199a72501a5461ca99497 fixup! First commit to my-source
</span><span class="line">c0cf52f4a914641efdc635bbc6195b6bef084cdc Categories and other plugin stuff
</span><span class="line">021086446698443ee57858872e14e7ee8ca9e2e5 Remove deploy stuff that got added by mistake
</span><span class="line">24ee1df941679953529aabc3d0eef5727a44c094 First commit to my-source
</span><span class="line">7f49807d5c5651baccb6d66c504549713a7ae7d7 Site updated at 2015-01-05 15:12:45 UTC
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Then you autosquash the chain, selecting the commit previous to the fix</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">git rebase -i --autosquash 7f49807d5c5651baccb6d66c504549713a7ae7d7
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>The result is a new chain</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">c927d675189eedd89d972663e2ef0ffe1438f4f7 Categories and other plugin stuff
</span><span class="line">e08ef8e27b3fd3c15e07a5e032e66a67a533ca3d Remove deploy stuff that got added by mistake
</span><span class="line">7d94aace9629272848382abfc217282c676f108e First commit to my-source
</span><span class="line">7f49807d5c5651baccb6d66c504549713a7ae7d7 Site updated at 2015-01-05 15:12:45 UTC
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Where the new <code>7d94aace9629272848382abfc217282c676f108e</code> contains the modifications needed.</p>

<p>In case the commit we want to fix is on top of the chain, the autosquash is simpler:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">git rebase -i --autosquash HEAD~2
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>If I had pushed my branch to the remote repository, then I would have to force push, since there is no way my local
branch and the remote one are compatible. To do that, you need to be pretty sure nobody is in the process of
committing anything to that particular branch (this is not a problem if you are working on this feature on your own),
and issue</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">git push origin newfeature -f
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Where origin is my remote repository name and <code>-f</code> overwrites the remote contents.</p>

<h3 id="final-thoughts">Final thoughts</h3>

<p>We can see that we can modify our commit chain (resetting our branch head or fixing commits). Some people say it changes
the history, but I don’t see it that way). The true history is in the <strong>reflog</strong>.</p>

<p>Also, people might find it difficult to think of the usefulness of having several remote repositories. For example, this
blog has a remote which is, obviously, Github pages, and it is where the stuff under <code>_deploy</code> gets sebt.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/01/06/hackintosh/">Hackintosh</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2015-01-06T01:24:36+01:00'><span class='date'><span class='date-month'>Jan</span> <span class='date-day'>6</span><span class='date-suffix'>th</span>, <span class='date-year'>2015</span></span> <span class='time'>1:24 am</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>I got an ASUS K55VD laptop nearly two years ago and the motherboard broke down without possibility of repair. Not being
able to repair it (I had several technical service shops working on it) was a sting on my heart. Then I recently spotted
an ASUS K55A motherboard (essentially the same except the NVidia 610M chip and no 2 GB external video RAM soldered into
the motherboard) on eBay. That was good enough for me, and I got the item for a very good price.</p>

<p>I managed to assemble the thing and I was lucky enough to get it working. So I ended up with two similar configurations.
I have a decent Ubuntu virtual machine on my Windows laptop, and I use it to play some games from time to time, so I
wanted this spare laptop to be useful in some other meaningful sense. It occurred to me that I could install Mac OSX
and have access to Apple’s tools to compile iOS apps for the iPhone.</p>

<p>Well, you must know that surfing the world of Hackintosh is overwhelming. The hacking is so volatile and the dependency
on each piece of hardware so extreme, that it becomes a pain in the ass for anybody. I don’t know whether to praise or
take pity of the Hackintosh scene such as Tonymacx86, RehabMan, Niresh, etc.</p>

<p>Well, I had a Mac virtual machine on my other laptop, so I downloaded Yosemite and created an installation USB. First
problem, my USB is not bootable. I don’t know whether this problem came from creating it from the virtual machine
(which needs to access the hardware in a non-native way through the host OS), but this was solved by using my Ubuntu
installation to create a HFS+ bootable partition with gParted (subsequent retries with Apple’s disk utility crashed my OSX VM).
With a bootable USB HFS+ partition, I could create a Yosemite installation USB with <a href="http://www.tonymacx86.com/445-unibeast-install-os-x-yosemite-any-supported-intel-based-pc.html">Unibeast</a>.
I must add that I got the Niresh distribution of Mountain Lion and Mavericks, but could not make it work either
(I don’t remember what the problem was).</p>

<p>Now, booting into the setup, I had some problems with my laptop keyboard and mouse not being recognized, so there was no
possibility of installing the software. What I did was installing <a href="http://www.tonymacx86.com/multibeast/">Multibeast</a>
<strong>on the USB drive</strong>, adding PS/2 Mouse and Keyboard support in the Multibeast menu (again from the 
virtual machine, to the created USB). With a workable-enough USB installation drive, I removed my previous Windows
partition and installed the vanilla Mac OSX. Then I added the same multibeast support. After booting, my motherboard
would not show my OSX installation as a boot option. I could only boot with my USB and choosing the installation as
partition to start from. I decided to use the <a href="http://sourceforge.net/projects/cloverefiboot/">Clover</a> bootloader,
which allowed my motherboard to show an EFI startup partition. After some more tweaking, this allowed me to boot from
my Mac OS X installation. Full resolution, no sound. To get sound, I installed VoodooHDA, which created audio feedback.
To solve this, the iGain setting from the VoodooHDA config panel must be set to low or zero. The configuration does not
persist, so one might choose to edit the kext <code>Config.plist</code> and set it there (and rebuild the caches!!!) or use
the VoodooHDA panel config (I don’t quite remember the details of this so you better google it).</p>

<p>I noticed a blinking effect when the computer showed the login screen, and investigating it further revealed that I had
no graphics acceleration. Injecting the 0x01660003 code in Clover had no effect, nor did using any other boot flag. At
this point I was desperate. I decided to run Multibeast once again against my OS X installation and install pretty much
any appealing driver. This (albeit some minor problems with the PS/2 drivers causing a halt in the boot process, solved
my manually deleting the drivers -and updating the cache!!!) granted me full graphics acceleration.</p>

<div class="bogus-wrapper"><notextile><!-- Image -->
<a id="img-6" class="imgModal floatRight" href="#imgModal-6" data-toggle="modal">
  <img src="/images/yosemite.png" width="342" height="192" title="Click for larger view." />
</a>
<div style="float: none;"></div>

<!-- Modal -->
<div class="modal fade" id="imgModal-6" tabindex="-1" role="dialog" aria-labelledby="imgModal-6Label" aria-hidden="true">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close" data-dismiss="modal" aria-hidden="true">&times;</button>
      </div>
      <div class="modal-body">
        <img src="/images/yosemite.png" width="1366" height="768" />
      </div>
      <div class="modal-footer">
        <button type="button" class="btn btn-primary" data-dismiss="modal">Close</button>
      </div>
    </div><!-- /.modal-content -->
  </div><!-- /.modal-dialog -->
</div><!-- /.modal --></notextile></div>

<p>The Wifi card of this laptop (AR5B925) is not compatible since Apple has not released kexts for this chip, nor has any
hacker done so. I got hold of an AR5B97 which is compatible, and installing the <a href="http://www.tonymacx86.com/network/104850-guide-airport-pcie-half-mini-v2.html">toledaARPT.kext</a>
with the Kext Helper. It is wonderful now to have Internet conectivity, though the Bluetooth is nowhere to be seen,
despite this card having it.</p>

<p>This is it, a process that spanned several days summarized in a small post. I hope it provides you with clues if your
issues are simmilar, but then again, everybody gets different symptoms when dealing with his own Hackintosh.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/01/01/principal-component-analysis/">Principal Component Analysis</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2015-01-01T01:22:01+01:00'><span class='date'><span class='date-month'>Jan</span> <span class='date-day'>1</span><span class='date-suffix'>st</span>, <span class='date-year'>2015</span></span> <span class='time'>1:22 am</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Principal Component Analysis is a classical statistical technique that aims at finding a transformation of the
input or measured variables so that the transformed variables offer a view of the data that maximizes the presented
“information” about the dataset. This allows for dimensionality reduction, since we can select a number of dimensions
which provide most of the “information” and be sure that each of the rest of the discarded dimensions contain less
information than each of the dimensions we have retained.</p>

<p>We start by requesting something as simple as our solution to be a constrained linear combination (so that the
coefficient vector is of norm one) so that it is of maximum square norm.</p>

<script type="math/tex; mode=display">
\max_{\|\mathbf{w}\|=1}  || \mathbf{X} \mathbf{w} ||^2 \\
\mbox{s.t. }  \mathbf{w}^T \mathbf{w_i} = 0
</script>

<p>Maximizing the square norm explains why the first component of non-centered data contains some kind of a data average
for example, the first <a href="http://scikit-learn.org/stable/auto_examples/decomposition/plot_faces_decomposition.html">eigenface</a> .</p>

<div class="bogus-wrapper"><notextile><!-- Image -->
<a id="img-4" class="imgModal floatRight" href="#imgModal-4" data-toggle="modal">
  <img src="/images/plot_faces_decomposition_002.png" width="300" height="226" title="Click for larger view." />
</a>
<div style="float: none;"></div>

<!-- Modal -->
<div class="modal fade" id="imgModal-4" tabindex="-1" role="dialog" aria-labelledby="imgModal-4Label" aria-hidden="true">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close" data-dismiss="modal" aria-hidden="true">&times;</button>
      </div>
      <div class="modal-body">
        <img src="/images/plot_faces_decomposition_002.png" width="600" height="451" />
      </div>
      <div class="modal-footer">
        <button type="button" class="btn btn-primary" data-dismiss="modal">Close</button>
      </div>
    </div><!-- /.modal-content -->
  </div><!-- /.modal-dialog -->
</div><!-- /.modal --></notextile></div>

<p>where, in the case of the first principal component, there is no $i$ less than one and the constraint does not apply.</p>

<p>Since the scalar product induces a norm, $ \mathbf{w}^T \mathbf{w}$ is the norm of $\mathbf{w} $ and the above becomes</p>

<p>Let $\mathbf{X}$ be the data matrix, let $\mathbf{\Sigma} = \mathbf{X}^T \mathbf{X}$ be the covariance matrix.</p>

<script type="math/tex; mode=display">
\max_{\|\mathbf{w}\|=1}  \mathbf{w}^T \mathbf{\Sigma} \mathbf{w} \\
\mbox{s.t. }  \mathbf{w}^T \mathbf{w_i} = 0
</script>

<p>For the first principal component, this is an quadratical optimization problem constrained to unitary norm of the
solution. This can be written as the optimization of a Rayleigh quotient.</p>

<script type="math/tex; mode=display">
\max_{\mathbf{w}} \frac{\mathbf{w}^T \mathbf{\Sigma} \mathbf{w}}{||\mathbf{w}||^2} \\
\max_{\mathbf{w}} \frac{\mathbf{w}^T \mathbf{\Sigma} \mathbf{w}}{\mathbf{w}^T \mathbf{w}} \\
</script>

<p>This is a Rayleigh quotient and it is well known from Matrix Analysis that the solution is in terms of the eigenvector
corresponding to the largest (positive) eigenvalue for covariance matrices (positive definite). 
Remember that $ ||\mathbf{w}|| = 1 \rightarrow  ||\mathbf{w}|| = ||\mathbf{w}||^2 = \mathbf{w}^T \mathbf{w} = 1$.
The same result can be
computed from Lagrangian constrained optimization. Taking derivatives and equating to zero</p>

<script type="math/tex; mode=display">
\frac{\partial}{\partial \mathbf{w}} \left( \mathbf{w}^T \mathbf{\Sigma} \mathbf{w} - \lambda \left(\mathbf{w}^T \mathbf{w} - 1\right) \right) = 0 \\
\mathbf{\Sigma} \mathbf{w} - \lambda \mathbf{w} = 0
</script>

<p>We arrive at</p>

<script type="math/tex; mode=display">
\mathbf{\Sigma} \mathbf{w}  = \lambda \mathbf{w}
</script>

<p>Which is an eigenvalue problem (and given the nature of $\mathbf{\Sigma}$, a symmetric one, which benefits from efficient
methods to arrive at solutions. The solution to the maximization problem is the eigenvector corresponding to the largest
eigenvalue. Subsequent components, given orthogonality constraints, are computed with subsequent eigenvectors.</p>

<p>Let $\mathbf{U}$ and $\mathbf{D}$ the eigenvector matrix (where the eigenvectors of
$\mathbf{\Sigma}$ are the columns of $\mathbf{U}$) and the eigenvalue matrix with the eigenvalues placed in the diagonal,
I usually choose to add the eigenvalue information to the weight combination matrix $\mathbf{W}$ to account for
component spread, but this is of no practical consequence (you can choose to take $\mathbf{W}=\mathbf{U}$, which amounts
to stacking up the vectors $\mathbf{w}$ in columns).</p>

<script type="math/tex; mode=display">
\mathbf{W} = \mathbf{U} \mathbf{D}^{\frac{1}{2}}
</script>

<p>And the transformation of the data is</p>

<script type="math/tex; mode=display">
\mathbf{Z} = \mathbf{X} \mathbf{W}
</script>

<h3 id="probabilistic-derivation">Probabilistic derivation</h3>

<p>I consider the probabilistic derivation a landmark since a lot of methods have been derived afterwards following
this approach. The seminal paper is <a href="http://research.microsoft.com/pubs/67218/bishop-ppca-jrss.pdf">“Probabilistic Principal Component Analysis”, by M. E. Tipping and C. M. Bishop</a>,
published in The Journal of the Royal Statistical Society, Series B.</p>

<p>The probabilistic approach has several benefits, for example, a natural way of handling incomplete data and obtain
transformations even in the presence of missing attributes. This, however, has been rarely implemented on software
packages.  The <a href="http://rgm3.lab.nig.ac.jp/RGM/R_rdfile?f=pcaMethods/man/ppca.Rd&amp;d=R_BC">Probabilistic PCA R Package</a>
supports incomplete data.</p>

<h3 id="playground-with-sklearn-and-r">Playground with Sklearn and R</h3>

<p>In IPython Notebook, open up a new sheet and import the necessary modules</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="kn">import</span> <span class="nn">matplotlib</span>
</span><span class="line"><span class="kn">import</span> <span class="nn">datetime</span>
</span><span class="line"><span class="kn">from</span> <span class="nn">matplotlib.finance</span> <span class="kn">import</span> <span class="n">quotes_historical_yahoo</span>
</span><span class="line"><span class="kn">from</span> <span class="nn">matplotlib.dates</span> <span class="kn">import</span> <span class="n">YearLocator</span><span class="p">,</span> <span class="n">MonthLocator</span><span class="p">,</span> <span class="n">DateFormatter</span>
</span><span class="line"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
</span><span class="line"><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
</span><span class="line"><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Define the date range that we are going to extract prices from</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">date1</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">date</span><span class="p">(</span><span class="mi">2004</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span class="line"><span class="n">date2</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">date</span><span class="p">(</span><span class="mi">2013</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Get the historical data</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">intc</span> <span class="o">=</span> <span class="n">quotes_historical_yahoo</span><span class="p">(</span><span class="s">&quot;INTC&quot;</span><span class="p">,</span> <span class="n">date1</span><span class="p">,</span> <span class="n">date2</span><span class="p">)</span>
</span><span class="line"><span class="n">msft</span> <span class="o">=</span> <span class="n">quotes_historical_yahoo</span><span class="p">(</span><span class="s">&quot;MSFT&quot;</span><span class="p">,</span> <span class="n">date1</span><span class="p">,</span> <span class="n">date2</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Extract the closing price from the data</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">cintc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">q</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">q</span> <span class="ow">in</span> <span class="n">intc</span><span class="p">])</span>
</span><span class="line"><span class="n">cmsft</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">q</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">q</span> <span class="ow">in</span> <span class="n">msft</span><span class="p">])</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Build a data matrix to be fed to the PCA implementation in a suitable format</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">cintc</span><span class="p">,</span><span class="n">cmsft</span><span class="p">))</span><span class="o">.</span><span class="n">T</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Plot both closing prices so that we can visually compare them with the transforms</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><img src="/images/pca_intc_msft_stocks.png" /></p>

<p>Build the object</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Transform the data</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">T</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Let’s examine the variance ratio explained by each of the components. Notice that the first component explains a lot
of the price movement of both stocks.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>with 0.8132162 and 0.1867838 of the variance explained by the components. Now we can print out the PCA transformation</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">plot</span><span class="p">(</span><span class="n">T</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><img src="/images/pca_intc_msft_transform.png" /></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/12/30/equality-of-means-statistical-test/">Equality of Means Statistical Test Made Easy</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2014-12-30T01:22:01+01:00'><span class='date'><span class='date-month'>Dec</span> <span class='date-day'>30</span><span class='date-suffix'>th</span>, <span class='date-year'>2014</span></span> <span class='time'>1:22 am</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>I never realized how difficult it was to understand a simple statistical concept such as the test for equality of means
until I had to explain it to my little sister. And I found out that this difficulty stemmed from poor explanations of
my professors and even worse from the textbooks I used to study it. I always ended up using the cookbook recipe,
stating the null hypothesis, performing the computations and stating the results in the correct statistical language.
I never had to explain it in my academic life so I never confronted this particular piece of knowledge and the root of
its difficulty.</p>

<p>My little sister could not understand the meaning of (talking about box plots):</p>

<blockquote><p>If the notches overlap, we reject the null hypothesis (that the means are different) at the 95% level.</p></blockquote>

<p>Even more, the textbook was talking about medians, which made the whole thing a lot more convoluted.</p>

<p>I was shocked, and certainly ashamed, I could not even begin to articulate any word. I was naked, I didn’t know anything
about it. “OK”, I thought, “let’s start from the beginning. What do you <em>really</em> want to do? What you want to do is
test if the two medians of both populations are equal or not, in a statistical sense”. I located a perniciously hidden
important constraint: The variables are normally distributed. “OK, that’s it”. Since their distribution is normal, 
which is symmetrically distributed around the mean, the median turns out to be the mean (and also the mode). The test
is reduced to an equality of means. Now, what would I do with two averages of two samples taken from two normally
distributed populations? For that, one must recall the difference between the average and the mathematical expectation
of a probability distribution (the first moment). The average is an aggregate of the different values of a sample.</p>

<script type="math/tex; mode=display">
\bar{x} = \frac{1}{N} \sum_{i=1}^N x_i
</script>

<p>Each of the values come from a distribution, which means that each of them is a random variable that acquires a
particular value. This means that the aggregate is also normally distributed.</p>

<script type="math/tex; mode=display">
\bar{X} = \frac{1}{N} \sum_{i=1}^N X_i \sim N(\mu, \sigma)
</script>

<p>This $\mu$ is the mathematical expectation. Recall that this is a linear operator in the functional analytic sense
of the word <em>operator</em>, that takes a function (probability density) and spits a number in the field the distribution
domain is a subset of (we assume it is the real numbers).</p>

<p>If the random variable is discrete, the operator $E[\cdot] : \ell \rightarrow \mathbb{R}$ is defined as</p>

<script type="math/tex; mode=display">
E[X] = \sum_{i \in \mathbb{I}} x_i p_i
</script>

<p>If it is otherwise continuous, $E[\cdot] : \mathbb{F} \rightarrow \mathbb{R}$ is:</p>

<script type="math/tex; mode=display">
E[X] = \int_{\mathbb{X}} x p(x) dx
</script>

<p>Where $\ell$ (for the lack of a better symbol) is a set of number sequences and $\mathbb{F}$ is a space of functions
whose analysis lies beyond the purpose of this post (just treat them as sets that contain respectively discrete and
continuous density functions). And $p$ (and $p_i$) is the probability density function or the density frequencies.</p>

<p>Then, we know by the law of large numbers that the average converges to the mathematical expectation as the number
of data $N$ tends to infinity.</p>

<script type="math/tex; mode=display">
\bar{x} \rightarrow E[X] = \mu
</script>

<p>Now, with two random variables $X$ and $Y$, under the null hypothesis, their mathematical expectation, or population
means, are the same:</p>

<script type="math/tex; mode=display">
H_0 : \mu_X = \mu_Y
</script>

<p>So that $\mu_0 - \mu_1 = 0$. This is, the difference must be zero. Now, this is a technicality: The difference is a new
random variable $F=X-Y$ with $E[X-Y]=E[X]-E[Y]=0$ because the operator is linear and the variables
come from the same distribution. <em>This difference is what we use in the test</em>. If we knew more about how it is
distributed, <em>we could query it for possible values to statistically validate the null hypothesis</em> $H_0$. </p>

<p>It turns out that this new difference random variable is also normally distributed and centered
around zero. We can then compute te standard deviation and fix the shape of the distribution, and place a confidence
interval so that the value resulting of the difference of means falls within the 95% of probability density around zero.
This means that if the sample difference is larger that the percentile enclosing this 95% of probability, we are not
<em>accepting</em> the null hypothesis (remember, that $\mu_X = \mu_Y$). Note that with probability 0.05, we are going to get a
sample difference larger than that percentile. For this reason, one does not say <em>reject</em>: There is a chance that the
population means are truly different, bit there is also a small (0.05 probability) chance that, being the population
means the same, we got difference of averages larger than the boundary percentile).</p>

<p>Of course, <em>the true statistical test is divided by a kind of standard deviation made up of an aggregate of the variances
of both samples, which makes the statistic be distributed as a t distribution. Otherwise the test would have no power.</em></p>

<p>To sum up, the statistical test for equality of means is:</p>

<ul>
  <li>Two samples from two populations.</li>
  <li>I want to know whether the means are equal.</li>
  <li>Under the hypothesis that they are equal (constrained to normality of populations and independence of samples):
    <ul>
      <li>The difference of means is zero</li>
      <li>Therefore, the difference between sample averages must be small, and it is a random variable itself that must be
normally distributed around zero.</li>
      <li>Once we compute the standard deviation, and hence the shape of this normal distribution of the difference, we
can select the interval to achieve the desired probability to find the value difference of means in the range,
say, 95%. If it falls outside, then we do not accept the null hypothesis (that the difference is zero). We do
this because it should be extremely rare for us to find two samples whose average difference falls ourside the
range (5%) if the null hypothesis is true.</li>
      <li>If it falls inside the 95% range, then there is no statistical evidence against the null hypothesis.</li>
    </ul>
  </li>
</ul>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/posts/2">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2015/04/09/manipulating-svg-images-from-browser-javascript/">Manipulating SVG Images From Browser Javascript</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/03/25/installing-theano-on-windows/">Installing Theano on Windows</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/03/08/the-monty-hall-problem-my-explanation/">The Monty Hall Problem (My Explanation)</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/02/26/powering-up-python-as-a-data-analysis-platform/">Powering Up Python as a Data Analysis Platform</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/02/20/image-pan-sharpening-with-pca/">Image Pan-sharpening With PCA</a>
      </li>
    
  </ul>
</section>
<section>
    <h1>Categories</h1>
    <ul id="category-list"><li><a href='/blog/categories/brainteasers'>brainteasers (1)</a></li><li><a href='/blog/categories/computation'>computation (6)</a></li><li><a href='/blog/categories/computing'>computing (1)</a></li><li><a href='/blog/categories/data-analysis'>data analysis (5)</a></li><li><a href='/blog/categories/hacking'>hacking (2)</a></li><li><a href='/blog/categories/image-processing'>image processing (1)</a></li><li><a href='/blog/categories/kernel-methods'>kernel methods (3)</a></li><li><a href='/blog/categories/machine-learning'>machine learning (4)</a></li><li><a href='/blog/categories/mathematics'>mathematics (5)</a></li><li><a href='/blog/categories/matlab'>matlab (1)</a></li><li><a href='/blog/categories/programming'>programming (6)</a></li><li><a href='/blog/categories/python'>python (3)</a></li><li><a href='/blog/categories/software-development'>software development (1)</a></li><li><a href='/blog/categories/statistics'>statistics (4)</a></li><li><a href='/blog/categories/tools'>tools (4)</a></li></ul>
</section>
<section>
    <h1>Tag Cloud</h1>
    <span id="tag-cloud"><a href='/blog/categories/brainteasers' style='font-size: 110.0%'>brainteasers</a> <a href='/blog/categories/computation' style='font-size: 160.0%'>computation</a> <a href='/blog/categories/computing' style='font-size: 110.0%'>computing</a> <a href='/blog/categories/data-analysis' style='font-size: 150.0%'>data analysis</a> <a href='/blog/categories/hacking' style='font-size: 120.0%'>hacking</a> <a href='/blog/categories/image-processing' style='font-size: 110.0%'>image processing</a> <a href='/blog/categories/kernel-methods' style='font-size: 130.0%'>kernel methods</a> <a href='/blog/categories/machine-learning' style='font-size: 140.0%'>machine learning</a> <a href='/blog/categories/mathematics' style='font-size: 150.0%'>mathematics</a> <a href='/blog/categories/matlab' style='font-size: 110.0%'>matlab</a> <a href='/blog/categories/programming' style='font-size: 160.0%'>programming</a> <a href='/blog/categories/python' style='font-size: 130.0%'>python</a> <a href='/blog/categories/software-development' style='font-size: 110.0%'>software development</a> <a href='/blog/categories/statistics' style='font-size: 140.0%'>statistics</a> <a href='/blog/categories/tools' style='font-size: 140.0%'>tools</a> </span>
</section><section>
    <script type="text/javascript" src="//rb.revolvermaps.com/0/0/6.js?i=1eyn18efppk&amp;m=7&amp;s=270&amp;c=e63100&amp;cr1=ffffff&amp;f=arial&amp;l=0&amp;bv=90&amp;lx=-420&amp;ly=420&amp;hi=20&amp;he=7&amp;hc=a8ddff&amp;rs=80" async="async"></script>
</section><section>
  <h3>Blogroll</h3>
  <!-- IMPORTANT: Do not change the below ID as it will affect the functioning of the plugin-->
    <ul id="blogroll-list"><li><a href='http://blog.cognitect.com/' feedurl='http://blog.cognitect.com/blog?format=rss' title = 'Clojure, ClojureScript, Datomic, Programming'>Cognitec</a></li><li><a href='http://www.datasciencecentral.com/' feedurl='http://feeds.feedburner.com/FeaturedBlogPosts-DataScienceCentral?format=xml' title = 'Big Data, Data Mining, Machine Learning'>Data Science Central</a></li><li><a href='http://www.datasciencecentral.com/' feedurl='http://feeds.feedburner.com/ResearchDiscussions-DataScienceCentral?format=xml' title = 'Big Data, Data Mining, Machine Learning'>Data Science Central</a></li><li><a href='http://deeplearning.net' feedurl='http://deeplearning.net/feed/' title = 'Deep Learning, Neural Networks'>deeplearning.net</a></li><li><a href='http://hunch.net' feedurl='http://feeds2.feedburner.com/MachineLearningtheory' title = 'Machine Learning, Data Mining'>Hunch.net</a></li><li><a href='http://blog.kaggle.com' feedurl='http://blog.kaggle.com/feed/' title = 'Data mining, Big Data, Machine Learning, Competitions'>Kaggle</a></li><li><a href='http://www.kdnuggets.com/' feedurl='http://feeds.feedburner.com/kdnuggets-data-mining-analytics?format=xml' title = 'Data Mining, Big Data, Machine Learning'>KDnuggets</a></li><li><a href='http://www.thoughtworks.com/' feedurl='http://feeds.feedburner.com/thoughtworks-blogs?format=xml' title = 'Programming, Software Engineering'>Thoughtworks</a></li><li><a href='http://engineeringblog.yelp.com' feedurl='http://engineeringblog.yelp.com/feed' title = 'Big Data, Machine Learning, Text Mining'>Yelp Engineering</a></li></ul>
    
    <script type="text/javascript">
      $(document).ready(function(){
        updateFeeds(true);
      });
    </script>
    <script src="/javascripts/tinysort-min.js"></script>
    <script src="/javascripts/blogroll.js"></script>
    
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/analyticbastard">@analyticbastard</a> on GitHub
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'analyticbastard',
            count: 0,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2015 - Analytic Bastard -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>






<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  jax: ["input/TeX", "output/HTML-CSS"],
  tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$']],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  messageStyle: "none",
  "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
});
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>

</body>
</html>
