<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Computation - Programming | The Analytic Bastard]]></title>
  <link href="http://analyticbastard.github.io/blog/categories/computation-programming/atom.xml" rel="self"/>
  <link href="http://analyticbastard.github.io/"/>
  <updated>2014-12-14T20:38:15+00:00</updated>
  <id>http://analyticbastard.github.io/</id>
  <author>
    <name><![CDATA[Analytic Bastard]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Current Computer Langage Market]]></title>
    <link href="http://analyticbastard.github.io/blog/2014/11/08/current-computer-langage-market/"/>
    <updated>2014-11-08T02:33:09+00:00</updated>
    <id>http://analyticbastard.github.io/blog/2014/11/08/current-computer-langage-market</id>
    <content type="html"><![CDATA[<p>There is an interesting series of articles on <a href="http://www.drdobbs.com/open-source/the-rise-and-fall-of-languages-in-2013/240165192">Dr. Dobb’s</a> essentially about what we can call the computer languages market, where they analyze trends and caracteristics, especially in the Editor in chief’s article.</p>

<p>They analyze the trends in language usage, which ordinally had not change since the year before (C, Java, Objective-C, C++, C#, PHP, Visual Basic, Python and Javascript), but that show a number of developments. For instance, Perl is leaving room in favor of Python. Perl seems to be dying and with signs of becoming history. They also mentioned a strong resurgence of Javascript but I would like to add that a large number of developments in the web scripting world have been carried out, starting with CoffeeScript, a tiny language that translates 1-to-1 to JavaScript. See their web page for some use of the language. ClojureScript is another compiler, this time to translate Clojure into JavaScript.</p>

<p>I found the following paragraph of particular interest (read more <a href="http://www.drdobbs.com/jvm/the-rise-and-fall-of-languages-in-2012/240145800">here</a>):</p>

<p><blockquote><p>By all measures, C++ use declined last year, demonstrating that C++11 was not enough to reanimate the language’s fortunes, despite the significant benefits it provides. I have previously opined that Microsoft’s contention of a return to native languages being led by C++ was unsupported by evidence. It is now clearly contradicted by the evidence.</p></blockquote></p>

<p>I feel encouraged by this statement. I believed C++ is an awful language, and always has been. Back in the late 90’s when I started programming and my teenage budget in a remote outpost included a non-disposable 486 DX2 with DOS, we had no choice but to get mainstream technical stuff, and that included C++ as the only advanced systems language. My experience, and I believe everybody’s experience, is that programmer’s time is more important than running time, and even hardcore C++ programmers recognize they put themselves in pain when facing non-standard tasks with the language. Some would argue that pain is what you pay for system performance, but that is not true (see the paragraph below). C++ will never grow on Big Data (data processing), mobile development or cloud computing, and I would expect that performance computing to also cut C++ usage in favor of more modern, maintainable system languages, such as the D language (or the one I describe below).</p>

<p>Another option they did not mention in the area of systems programming, more than the D language, is Nimrod. It has cool features such as pointers that are traced by a lightweight garbage collector and others that directly translate to C++ pointers. Templates that can be called as operators are included, supporting metaprogramming, it supports immutable objects, a number of syntactic sugars (such as being able to call len(x), x.len or x.len if there is only one argument, command and function-like calls like echo(“hello”) and echo “hello”…), first class functions and a very good mixture between Python indentation-defined blocks and Scala function definitions, as opposed to D’s C-like syntax. Nimrod compiles to C, C++, Objective C and JavaScript. Definitely a good candidate to learn and to watch.</p>

<p>On the functional but high-performant side of the market we have Erlang, Haskell, Scala and Clojure. The first three are older, especially the first two ones. In my opinion, Clojure is simplest, especially when compared to Scala. This is evident when examining a source code listing in both languages. Clojure lifts the programmer’s productivity to new heights.
It is worth mentioning at this point that there is a new promising contender in the field. It is <a href="http://drmeister.wordpress.com/2014/09/18/announcing-clasp/">Clasp</a>, a Common Lisp 2.0 compliant language that works with native C++ libraries with interoperability via the LLVM compiler framework. It is still in its inception and in a very alpha stage, but the prospective of using functional tools in a Lisp way with native C++ objects promises to raise productivity whenever time is of the essence. </p>

<p><sub>This post is part of my old blog. See the original <a href="http://machinomics.blogspot.com.es/2014/02/on-computer-languages-market.html">here</a></sub></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Naive Bayes Implemented With Map/Reduce Operations]]></title>
    <link href="http://analyticbastard.github.io/blog/2014/11/05/naive-bayes-implemented-with-map-slash-reduce-operations/"/>
    <updated>2014-11-05T11:02:16+00:00</updated>
    <id>http://analyticbastard.github.io/blog/2014/11/05/naive-bayes-implemented-with-map-slash-reduce-operations</id>
    <content type="html"><![CDATA[<p>I made a fairly straightforward implementation of the Naive Bayes classifier for discrete data is using Map Reduce. This is especially useful if you have a bunch of characteristic or naturally discrete data that you can exploit, such as presence/absence, amount of clicks, page/item visited or not, etc.</p>

<p>This can be achieved by first using the data attributes as the key, and the labels as the values on the mapper, in which we need to process the keys and values in this way:</p>

<ul>
  <li>emit the label as key</li>
  <li>for each variable (attribute) emit its index (for example, column index) also as key</li>
</ul>

<p>We only need to emit the category (attribute value) as the value</p>

<p>In the reducer, we need to scan each category and find out how many of the elements in the current key belong to to a category, and divide by the sum of all its categories (which are our values) all which constitutes</p>

<script type="math/tex; mode=display">
P(X_i=x_{i,0}|y=y_0)
</script>

<p>for which we emit a triplet</p>

<ul>
  <li>emit the label as key</li>
  <li>for each variable (attribute) emit its index (for example, column index) also as key</li>
  <li>emit the category for this attribute of this example</li>
</ul>

<p>As value we only need to emit the previous division.</p>

<p>To find out a new instance, we look into the dictionary entry corresponding to its attributes and return the bayes quotient.</p>

<p>I’ve just implemented this in MyML. </p>

<p>As an example its usage, we consider two random uniform variables <script type="math/tex">\[0,1\]</script> and its classification depends on the sum 
being more than one. Now we compute the observed variables by rounding the originals up or down, with the corresponding
information loss in the process.</p>

<p>&#8220;`python
import numpy as np
Xd=np.random.random((256,2))
X=1<em>(Xd&lt;.5)
y=1</em>(Xd.sum(axis=1)&lt;.5)</p>

<p>from myml.supervised import bayes</p>

<p>reload(bayes)
nb = bayes.NaiveBayes()
nb.fit(X, y)
nb.predict(X[0,:])
pred=nb.predict(X)</p>

<h1 id="now-we-predict-the-whole-dataset">Now we predict the (whole) dataset</h1>
<p>1.0<em>np.sum(1.0</em>(pred&gt;.5).reshape((1,len(y)))[0]==y)/len(y) </p>

<p>0.89453125</p>

<p>&#8220;`</p>
]]></content>
  </entry>
  
</feed>
